{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raw_text_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5nXMIL88792ZNEHIqTCLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vam564/Python-Files/blob/main/raw_text_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u91vbCKvuuUt",
        "outputId": "9fd66623-3983-4edb-a920-e886957e4aa5"
      },
      "source": [
        "import nltk, re, pprint\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('book')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQOghgOI8WU6",
        "outputId": "0582ece9-1eac-43ae-aebe-3792416dd22f"
      },
      "source": [
        "#1\n",
        "from urllib import request\n",
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf8')\n",
        "tokens = word_tokenize(raw[:200])\n",
        "len(tokens)\n",
        "porter = nltk.PorterStemmer()\n",
        "lancaster = nltk.LancasterStemmer()\n",
        "a = [porter.stem(t) for t in tokens]\n",
        "b = [lancaster.stem(t) for t in tokens]\n",
        "print(\"Porter Stem : Lancaster Stem\")\n",
        "for i in range(0,len(a)):\n",
        "  print(a[i] +\" : \"+ b[i])\n",
        "a == b\n",
        "# This says the Porter and the Lancaster stemmers aren't same. There is a difference. Both follow differenet stripping affixes approach."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stem : Lancaster Stem\n",
            "﻿the : ﻿the\n",
            "project : project\n",
            "gutenberg : gutenberg\n",
            "ebook : ebook\n",
            "of : of\n",
            "crime : crim\n",
            "and : and\n",
            "punish : pun\n",
            ", : ,\n",
            "by : by\n",
            "fyodor : fyod\n",
            "dostoevski : dostoevsky\n",
            "thi : thi\n",
            "ebook : ebook\n",
            "is : is\n",
            "for : for\n",
            "the : the\n",
            "use : us\n",
            "of : of\n",
            "anyon : anyon\n",
            "anywher : anywh\n",
            "in : in\n",
            "the : the\n",
            "unit : unit\n",
            "state : stat\n",
            "and : and\n",
            "most : most\n",
            "other : oth\n",
            "part : part\n",
            "of : of\n",
            "the : the\n",
            "world : world\n",
            "at : at\n",
            "no : no\n",
            "cost : cost\n",
            "and : and\n",
            "with : with\n",
            "a : a\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANWfcG2i8feV",
        "outputId": "559ac332-b61a-4d55-d492-bb914fbb9f62"
      },
      "source": [
        "#2\n",
        "from operator import itemgetter\n",
        "from nltk.corpus import brown\n",
        "list_words = brown.words()\n",
        "a = list(list_words[:100])\n",
        "x = sorted(a, key=itemgetter(0))\n",
        "y = sorted(a, key=itemgetter(-1))\n",
        "print(x)\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"''\", \"''\", \"''\", ',', ',', '.', '.', \"Atlanta's\", 'Atlanta', 'County', 'City', 'Committee', 'City', 'Court', 'Durwood', 'Executive', 'Fulton', 'Friday', 'Fulton', 'Grand', 'Ivan', 'Jury', 'Judge', 'Mayor-nominate', 'Pye', 'September-October', 'Superior', 'The', 'The', 'The', '``', '``', '``', 'an', 'any', 'and', 'been', 'by', 'by', 'charge', 'conducted', 'charged', 'deserves', 'election', 'evidence', 'election', 'election', 'further', 'for', 'had', 'had', 'hard-fought', 'investigation', 'irregularities', 'in', 'in', 'investigate', 'irregularities', 'in', 'jury', 'jury', 'manner', 'no', 'of', 'over-all', 'of', 'of', 'of', 'of', 'primary', 'produced', 'place', 'presentments', 'praise', 'possible', 'primary', 'recent', 'reports', 'said', 'said', 'that', 'took', 'term-end', 'that', 'the', 'the', 'the', 'thanks', 'the', 'the', 'the', 'term', 'to', 'the', 'which', 'which', 'was', 'which', 'was', 'won']\n",
            "[\"''\", \"''\", \"''\", ',', ',', '.', '.', '``', '``', '``', 'Atlanta', 'Grand', 'said', 'produced', 'said', 'term-end', 'had', 'and', 'conducted', 'had', 'charged', 'Durwood', 'The', 'evidence', 'place', 'The', 'the', 'Executive', 'Committee', 'charge', 'the', 'the', 'praise', 'the', 'the', 'the', 'The', 'Judge', 'Pye', 'investigate', 'possible', 'the', 'Mayor-nominate', 'of', 'of', 'of', 'of', 'of', 'which', 'which', 'which', 'took', 'over-all', 'term', 'Fulton', 'an', 'investigation', 'election', 'in', 'election', 'in', 'election', 'been', 'Fulton', 'in', 'won', 'Ivan', 'no', 'to', 'further', 'for', 'manner', 'September-October', 'Superior', \"Atlanta's\", 'irregularities', 'presentments', 'deserves', 'thanks', 'was', 'reports', 'irregularities', 'was', 'recent', 'that', 'that', 'Court', 'hard-fought', 'County', 'Jury', 'Friday', 'primary', 'any', 'jury', 'City', 'City', 'jury', 'by', 'primary', 'by']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SzlrVZN_d9T",
        "outputId": "c669134f-b9d0-4fd9-9f7a-84b615d05d24"
      },
      "source": [
        "#3\n",
        "from urllib import request\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def utility(url):\n",
        "  response_url = request.urlopen(url)\n",
        "  raw_text = response_url.read().decode('utf8')\n",
        "  raw_text = BeautifulSoup(raw_text, 'html.parser').get_text()\n",
        "  tokens = word_tokenize(raw_text)\n",
        "  return tokens\n",
        "\n",
        "utility(\"http://news.bbc.co.uk/2/hi/health/2284783.stm\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BBC',\n",
              " 'NEWS',\n",
              " '|',\n",
              " 'Health',\n",
              " '|',\n",
              " 'Blondes',\n",
              " \"'to\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'in',\n",
              " '200',\n",
              " \"years'\",\n",
              " 'NEWS',\n",
              " 'SPORT',\n",
              " 'WEATHER',\n",
              " 'WORLD',\n",
              " 'SERVICE',\n",
              " 'A-Z',\n",
              " 'INDEX',\n",
              " 'SEARCH',\n",
              " 'You',\n",
              " 'are',\n",
              " 'in',\n",
              " ':',\n",
              " 'Health',\n",
              " 'News',\n",
              " 'Front',\n",
              " 'Page',\n",
              " 'Africa',\n",
              " 'Americas',\n",
              " 'Asia-Pacific',\n",
              " 'Europe',\n",
              " 'Middle',\n",
              " 'East',\n",
              " 'South',\n",
              " 'Asia',\n",
              " 'UK',\n",
              " 'Business',\n",
              " 'Entertainment',\n",
              " 'Science/Nature',\n",
              " 'Technology',\n",
              " 'Health',\n",
              " 'Medical',\n",
              " 'notes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Talking',\n",
              " 'Point',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Country',\n",
              " 'Profiles',\n",
              " 'In',\n",
              " 'Depth',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Programmes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'SERVICES',\n",
              " 'Daily',\n",
              " 'E-mail',\n",
              " 'News',\n",
              " 'Ticker',\n",
              " 'Mobile/PDAs',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Text',\n",
              " 'Only',\n",
              " 'Feedback',\n",
              " 'Help',\n",
              " 'EDITIONS',\n",
              " 'Change',\n",
              " 'to',\n",
              " 'UK',\n",
              " 'Friday',\n",
              " ',',\n",
              " '27',\n",
              " 'September',\n",
              " ',',\n",
              " '2002',\n",
              " ',',\n",
              " '11:51',\n",
              " 'GMT',\n",
              " '12:51',\n",
              " 'UK',\n",
              " 'Blondes',\n",
              " \"'to\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'in',\n",
              " '200',\n",
              " \"years'\",\n",
              " 'Scientists',\n",
              " 'believe',\n",
              " 'the',\n",
              " 'last',\n",
              " 'blondes',\n",
              " 'will',\n",
              " 'be',\n",
              " 'in',\n",
              " 'Finland',\n",
              " 'The',\n",
              " 'last',\n",
              " 'natural',\n",
              " 'blondes',\n",
              " 'will',\n",
              " 'die',\n",
              " 'out',\n",
              " 'within',\n",
              " '200',\n",
              " 'years',\n",
              " ',',\n",
              " 'scientists',\n",
              " 'believe',\n",
              " '.',\n",
              " 'A',\n",
              " 'study',\n",
              " 'by',\n",
              " 'experts',\n",
              " 'in',\n",
              " 'Germany',\n",
              " 'suggests',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " 'are',\n",
              " 'an',\n",
              " 'endangered',\n",
              " 'species',\n",
              " 'and',\n",
              " 'will',\n",
              " 'become',\n",
              " 'extinct',\n",
              " 'by',\n",
              " '2202',\n",
              " '.',\n",
              " 'Researchers',\n",
              " 'predict',\n",
              " 'the',\n",
              " 'last',\n",
              " 'truly',\n",
              " 'natural',\n",
              " 'blonde',\n",
              " 'will',\n",
              " 'be',\n",
              " 'born',\n",
              " 'in',\n",
              " 'Finland',\n",
              " '-',\n",
              " 'the',\n",
              " 'country',\n",
              " 'with',\n",
              " 'the',\n",
              " 'highest',\n",
              " 'proportion',\n",
              " 'of',\n",
              " 'blondes',\n",
              " '.',\n",
              " 'The',\n",
              " 'frequency',\n",
              " 'of',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'drop',\n",
              " 'but',\n",
              " 'they',\n",
              " 'wo',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " 'Prof',\n",
              " 'Jonathan',\n",
              " 'Rees',\n",
              " ',',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'But',\n",
              " 'they',\n",
              " 'say',\n",
              " 'too',\n",
              " 'few',\n",
              " 'people',\n",
              " 'now',\n",
              " 'carry',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'for',\n",
              " 'blondes',\n",
              " 'to',\n",
              " 'last',\n",
              " 'beyond',\n",
              " 'the',\n",
              " 'next',\n",
              " 'two',\n",
              " 'centuries',\n",
              " '.',\n",
              " 'The',\n",
              " 'problem',\n",
              " 'is',\n",
              " 'that',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " 'is',\n",
              " 'caused',\n",
              " 'by',\n",
              " 'a',\n",
              " 'recessive',\n",
              " 'gene',\n",
              " '.',\n",
              " 'In',\n",
              " 'order',\n",
              " 'for',\n",
              " 'a',\n",
              " 'child',\n",
              " 'to',\n",
              " 'have',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " ',',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'on',\n",
              " 'both',\n",
              " 'sides',\n",
              " 'of',\n",
              " 'the',\n",
              " 'family',\n",
              " 'in',\n",
              " 'the',\n",
              " 'grandparents',\n",
              " \"'\",\n",
              " 'generation',\n",
              " '.',\n",
              " 'Dyed',\n",
              " 'rivals',\n",
              " 'The',\n",
              " 'researchers',\n",
              " 'also',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'so-called',\n",
              " 'bottle',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'be',\n",
              " 'to',\n",
              " 'blame',\n",
              " 'for',\n",
              " 'the',\n",
              " 'demise',\n",
              " 'of',\n",
              " 'their',\n",
              " 'natural',\n",
              " 'rivals',\n",
              " '.',\n",
              " 'They',\n",
              " 'suggest',\n",
              " 'that',\n",
              " 'dyed-blondes',\n",
              " 'are',\n",
              " 'more',\n",
              " 'attractive',\n",
              " 'to',\n",
              " 'men',\n",
              " 'who',\n",
              " 'choose',\n",
              " 'them',\n",
              " 'as',\n",
              " 'partners',\n",
              " 'over',\n",
              " 'true',\n",
              " 'blondes',\n",
              " '.',\n",
              " 'Bottle-blondes',\n",
              " 'like',\n",
              " 'Ann',\n",
              " 'Widdecombe',\n",
              " 'may',\n",
              " 'be',\n",
              " 'to',\n",
              " 'blame',\n",
              " 'But',\n",
              " 'Jonathan',\n",
              " 'Rees',\n",
              " ',',\n",
              " 'professor',\n",
              " 'of',\n",
              " 'dermatology',\n",
              " 'at',\n",
              " 'the',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'said',\n",
              " 'it',\n",
              " 'was',\n",
              " 'unlikely',\n",
              " 'blondes',\n",
              " 'would',\n",
              " 'die',\n",
              " 'out',\n",
              " 'completely',\n",
              " '.',\n",
              " '``',\n",
              " 'Genes',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'unless',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'disadvantage',\n",
              " 'of',\n",
              " 'having',\n",
              " 'that',\n",
              " 'gene',\n",
              " 'or',\n",
              " 'by',\n",
              " 'chance',\n",
              " '.',\n",
              " 'They',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " ',',\n",
              " \"''\",\n",
              " 'he',\n",
              " 'told',\n",
              " 'BBC',\n",
              " 'News',\n",
              " 'Online',\n",
              " '.',\n",
              " '``',\n",
              " 'The',\n",
              " 'only',\n",
              " 'reason',\n",
              " 'blondes',\n",
              " 'would',\n",
              " 'disappear',\n",
              " 'is',\n",
              " 'if',\n",
              " 'having',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'was',\n",
              " 'a',\n",
              " 'disadvantage',\n",
              " 'and',\n",
              " 'I',\n",
              " 'do',\n",
              " 'not',\n",
              " 'think',\n",
              " 'that',\n",
              " 'is',\n",
              " 'the',\n",
              " 'case',\n",
              " '.',\n",
              " '``',\n",
              " 'The',\n",
              " 'frequency',\n",
              " 'of',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'drop',\n",
              " 'but',\n",
              " 'they',\n",
              " 'wo',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " '.',\n",
              " \"''\",\n",
              " 'See',\n",
              " 'also',\n",
              " ':',\n",
              " '28',\n",
              " 'Mar',\n",
              " '01',\n",
              " '|',\n",
              " 'Education',\n",
              " 'What',\n",
              " 'is',\n",
              " 'it',\n",
              " 'about',\n",
              " 'blondes',\n",
              " '?',\n",
              " '09',\n",
              " 'Apr',\n",
              " '99',\n",
              " '|',\n",
              " 'Health',\n",
              " 'Platinum',\n",
              " 'blondes',\n",
              " 'are',\n",
              " 'labelled',\n",
              " 'as',\n",
              " 'dumb',\n",
              " '17',\n",
              " 'Apr',\n",
              " '02',\n",
              " '|',\n",
              " 'Health',\n",
              " 'Hair',\n",
              " 'dye',\n",
              " 'cancer',\n",
              " 'alert',\n",
              " 'Internet',\n",
              " 'links',\n",
              " ':',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'The',\n",
              " 'BBC',\n",
              " 'is',\n",
              " 'not',\n",
              " 'responsible',\n",
              " 'for',\n",
              " 'the',\n",
              " 'content',\n",
              " 'of',\n",
              " 'external',\n",
              " 'internet',\n",
              " 'sites',\n",
              " 'Top',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'now',\n",
              " ':',\n",
              " 'Heart',\n",
              " 'risk',\n",
              " 'link',\n",
              " 'to',\n",
              " 'big',\n",
              " 'families',\n",
              " 'Back',\n",
              " 'pain',\n",
              " 'drug',\n",
              " \"'may\",\n",
              " 'aid',\n",
              " \"diabetics'\",\n",
              " 'Congo',\n",
              " 'Ebola',\n",
              " 'outbreak',\n",
              " 'confirmed',\n",
              " 'Vegetables',\n",
              " 'ward',\n",
              " 'off',\n",
              " \"Alzheimer's\",\n",
              " 'Polio',\n",
              " 'campaign',\n",
              " 'launched',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'Gene',\n",
              " 'defect',\n",
              " 'explains',\n",
              " 'high',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Botox',\n",
              " \"'may\",\n",
              " 'cause',\n",
              " 'new',\n",
              " \"wrinkles'\",\n",
              " 'Alien',\n",
              " \"'abductees\",\n",
              " \"'\",\n",
              " 'show',\n",
              " 'real',\n",
              " 'symptoms',\n",
              " 'Links',\n",
              " 'to',\n",
              " 'more',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'are',\n",
              " 'at',\n",
              " 'the',\n",
              " 'foot',\n",
              " 'of',\n",
              " 'the',\n",
              " 'page',\n",
              " '.',\n",
              " 'E-mail',\n",
              " 'this',\n",
              " 'story',\n",
              " 'to',\n",
              " 'a',\n",
              " 'friend',\n",
              " 'Links',\n",
              " 'to',\n",
              " 'more',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'In',\n",
              " 'This',\n",
              " 'Section',\n",
              " 'Heart',\n",
              " 'risk',\n",
              " 'link',\n",
              " 'to',\n",
              " 'big',\n",
              " 'families',\n",
              " 'Back',\n",
              " 'pain',\n",
              " 'drug',\n",
              " \"'may\",\n",
              " 'aid',\n",
              " \"diabetics'\",\n",
              " 'Congo',\n",
              " 'Ebola',\n",
              " 'outbreak',\n",
              " 'confirmed',\n",
              " 'Vegetables',\n",
              " 'ward',\n",
              " 'off',\n",
              " \"Alzheimer's\",\n",
              " 'Polio',\n",
              " 'campaign',\n",
              " 'launched',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'Gene',\n",
              " 'defect',\n",
              " 'explains',\n",
              " 'high',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Botox',\n",
              " \"'may\",\n",
              " 'cause',\n",
              " 'new',\n",
              " \"wrinkles'\",\n",
              " 'Alien',\n",
              " \"'abductees\",\n",
              " \"'\",\n",
              " 'show',\n",
              " 'real',\n",
              " 'symptoms',\n",
              " 'How',\n",
              " 'sperm',\n",
              " 'wriggle',\n",
              " 'Bollywood',\n",
              " 'told',\n",
              " 'to',\n",
              " 'stub',\n",
              " 'it',\n",
              " 'out',\n",
              " 'Fears',\n",
              " 'over',\n",
              " 'tuna',\n",
              " 'health',\n",
              " 'risk',\n",
              " 'to',\n",
              " 'babies',\n",
              " 'Public',\n",
              " 'can',\n",
              " 'be',\n",
              " 'taught',\n",
              " 'to',\n",
              " 'spot',\n",
              " 'strokes',\n",
              " '^^',\n",
              " 'Back',\n",
              " 'to',\n",
              " 'top',\n",
              " 'News',\n",
              " 'Front',\n",
              " 'Page',\n",
              " '|',\n",
              " 'Africa',\n",
              " '|',\n",
              " 'Americas',\n",
              " '|',\n",
              " 'Asia-Pacific',\n",
              " '|',\n",
              " 'Europe',\n",
              " '|',\n",
              " 'Middle',\n",
              " 'East',\n",
              " '|',\n",
              " 'South',\n",
              " 'Asia',\n",
              " '|',\n",
              " 'UK',\n",
              " '|',\n",
              " 'Business',\n",
              " '|',\n",
              " 'Entertainment',\n",
              " '|',\n",
              " 'Science/Nature',\n",
              " '|',\n",
              " 'Technology',\n",
              " '|',\n",
              " 'Health',\n",
              " '|',\n",
              " 'Talking',\n",
              " 'Point',\n",
              " '|',\n",
              " 'Country',\n",
              " 'Profiles',\n",
              " '|',\n",
              " 'In',\n",
              " 'Depth',\n",
              " '|',\n",
              " 'Programmes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'Sport',\n",
              " '>',\n",
              " '>',\n",
              " '|',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'Weather',\n",
              " '>',\n",
              " '>',\n",
              " '|',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'World',\n",
              " 'Service',\n",
              " '>',\n",
              " '>',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '©',\n",
              " 'MMIII',\n",
              " '|',\n",
              " 'News',\n",
              " 'Sources',\n",
              " '|',\n",
              " 'Privacy',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'var',\n",
              " 'pCid=',\n",
              " \"''\",\n",
              " 'uk_bbc_0',\n",
              " \"''\",\n",
              " ';',\n",
              " 'var',\n",
              " 'w0=1',\n",
              " ';',\n",
              " 'var',\n",
              " 'refR=escape',\n",
              " '(',\n",
              " 'document.referrer',\n",
              " ')',\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " 'refR.length',\n",
              " '>',\n",
              " '=252',\n",
              " ')',\n",
              " 'refR=refR.substring',\n",
              " '(',\n",
              " '0,252',\n",
              " ')',\n",
              " '+',\n",
              " \"''\",\n",
              " '...',\n",
              " \"''\",\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'var',\n",
              " 'w0=0',\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'if',\n",
              " '(',\n",
              " 'w0',\n",
              " ')',\n",
              " '{',\n",
              " 'var',\n",
              " 'imgN=',\n",
              " \"'\",\n",
              " '<',\n",
              " 'img',\n",
              " 'src=',\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//server-uk.imrworldwide.com/cgi-bin/count',\n",
              " '?',\n",
              " \"ref='+\",\n",
              " 'refR+',\n",
              " \"'\",\n",
              " '&',\n",
              " \"cid='+pCid+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " 'width=1',\n",
              " 'height=1',\n",
              " '>',\n",
              " \"'\",\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " 'navigator.userAgent.indexOf',\n",
              " '(',\n",
              " \"'Mac\",\n",
              " \"'\",\n",
              " ')',\n",
              " '!',\n",
              " '=-1',\n",
              " ')',\n",
              " '{',\n",
              " 'document.write',\n",
              " '(',\n",
              " 'imgN',\n",
              " ')',\n",
              " ';',\n",
              " '}',\n",
              " 'else',\n",
              " '{',\n",
              " 'document.write',\n",
              " '(',\n",
              " \"'\",\n",
              " '<',\n",
              " 'applet',\n",
              " 'code=',\n",
              " \"''\",\n",
              " 'Measure.class',\n",
              " \"''\",\n",
              " \"'+\",\n",
              " \"'codebase=\",\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//server-uk.imrworldwide.com/',\n",
              " \"''\",\n",
              " \"'+'width=1\",\n",
              " 'height=2',\n",
              " '>',\n",
              " \"'+\",\n",
              " \"'\",\n",
              " '<',\n",
              " 'param',\n",
              " 'name=',\n",
              " \"''\",\n",
              " 'ref',\n",
              " \"''\",\n",
              " 'value=',\n",
              " \"''\",\n",
              " \"'+refR+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " '>',\n",
              " \"'+\",\n",
              " \"'\",\n",
              " '<',\n",
              " 'param',\n",
              " 'name=',\n",
              " \"''\",\n",
              " 'cid',\n",
              " \"''\",\n",
              " 'value=',\n",
              " \"''\",\n",
              " \"'+pCid+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " '>',\n",
              " '<',\n",
              " 'textflow',\n",
              " '>',\n",
              " \"'+imgN+\",\n",
              " \"'\",\n",
              " '<',\n",
              " '/textflow',\n",
              " '>',\n",
              " '<',\n",
              " '/applet',\n",
              " '>',\n",
              " \"'\",\n",
              " ')',\n",
              " ';',\n",
              " '}',\n",
              " '}',\n",
              " 'document.write',\n",
              " '(',\n",
              " '``',\n",
              " '<',\n",
              " 'COMMENT',\n",
              " '>',\n",
              " \"''\",\n",
              " ')',\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " 'var',\n",
              " 'si',\n",
              " '=',\n",
              " 'document.location+',\n",
              " \"''\",\n",
              " \"''\",\n",
              " ';',\n",
              " 'var',\n",
              " 'tsi',\n",
              " '=',\n",
              " 'si.replace',\n",
              " '(',\n",
              " '``',\n",
              " '.stm',\n",
              " \"''\",\n",
              " ',',\n",
              " \"''\",\n",
              " \"''\",\n",
              " ')',\n",
              " '.substr',\n",
              " '(',\n",
              " 'si.length-11',\n",
              " ',',\n",
              " 'si.length',\n",
              " ')',\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " '!',\n",
              " 'tsi.match',\n",
              " '(',\n",
              " '/\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d/',\n",
              " ')',\n",
              " ')',\n",
              " '{',\n",
              " 'tsi',\n",
              " '=',\n",
              " '0',\n",
              " ';',\n",
              " '}',\n",
              " 'document.write',\n",
              " '(',\n",
              " \"'\",\n",
              " '<',\n",
              " 'img',\n",
              " 'src=',\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//stats.bbc.co.uk/o.gif',\n",
              " '?',\n",
              " '~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~',\n",
              " \"'\",\n",
              " '+',\n",
              " 'tsi',\n",
              " '+',\n",
              " \"'~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~\",\n",
              " '(',\n",
              " 'none',\n",
              " ')',\n",
              " '~RS~a~RS~International~RS~q~RS~~RS~z~RS~13~RS~',\n",
              " \"''\",\n",
              " '>',\n",
              " \"'\",\n",
              " ')',\n",
              " ';']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uso79FjyEgrq",
        "outputId": "f57d258f-2052-4606-ac49-a0df0623e15c"
      },
      "source": [
        "#4\n",
        "text = [\"Whatever\", \"you\", \"do\" ,\"is\", \"good\" ,\"and\", \"do\", \"for\", \"youself\", \"Be\", \"yourself\"]\n",
        "voca=[\"do\",\"youself\"]\n",
        "def differences(text, voca):\n",
        "  return set.difference(set(text), set(voca))\n",
        "differences(text,voca)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Be', 'Whatever', 'and', 'for', 'good', 'is', 'you', 'yourself'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "LNqwApKxGIcX",
        "outputId": "58eed3eb-9a50-4ed6-9109-e522f8867b4f"
      },
      "source": [
        "#5\n",
        "from nltk import FreqDist\n",
        "# f = open('/root/nltk_data/corpora/gutenberg/austen-emma.txt', 'rU')\n",
        "# f.read()\n",
        "# lines_list = re.findall(r'*[\\.\\?!][\\'\"\\)\\]]*', f)\n",
        "\n",
        "with(open('/root/nltk_data/corpora/gutenberg/austen-emma.txt', 'r') as in_file):\n",
        "    text = in_file.read()\n",
        "    sents = nltk.sent_tokenize(text)\n",
        "print(sents)\n",
        "\n",
        "# for i in lines_list:\n",
        "#   if i == \" \":\n",
        "#     lines_list[i].remove()\n",
        "\n",
        "\n",
        "# d = []\n",
        "# for i in lines_list:\n",
        "#   d.append(FreqDist(i))\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-a9a1d72bd0af>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    with(open('/root/nltk_data/corpora/gutenberg/austen-emma.txt', 'r') as in_file):\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2Rl_p9oHfzz",
        "outputId": "1e3f0e49-3309-434b-d3fe-5d54b8a555c0"
      },
      "source": [
        "#5\n",
        "from nltk import FreqDist\n",
        "names = nltk.corpus.state_union\n",
        "all_text_files = names.fileids()\n",
        "lines = names.sents(all_text_files[0])\n",
        "all_words = names.words(all_text_files[0])\n",
        "freq_whole=[]\n",
        "for i in lines:\n",
        "  freq_whole.append(FreqDist(i))\n",
        "freq_sent = []\n",
        "freq_dist_sent = {}\n",
        "\n",
        "for index,i in enumerate(freq_whole):\n",
        "  s=0\n",
        "  for j in i.most_common(50):\n",
        "    s = s + j[1]\n",
        "    y = ' '.join(lines[index])\n",
        "    freq_dist_sent[y] = s\n",
        "\n",
        "\n",
        "\n",
        "sorted(freq_dist_sent.items(), key=lambda x: x[1], reverse=True)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('As I have assumed my heavy duties , I humbly pray Almighty God , in the words of King Solomon : \" Give therefore thy servant an understanding heart to judge thy people , that I may discern between good and bad ; for who is able to judge this thy so great a people ?\"',\n",
              "  56),\n",
              " ('While these great states have a special responsibility to enforce the peace , their responsibility is based upon the obligations resting upon all states , large and small , not to use force in international relations except in the defense of law .',\n",
              "  43),\n",
              " ('So much blood has already been shed for the ideals which we cherish , and for which Franklin Delano Roosevelt lived and died , that we dare not permit even a momentary pause in the hard fight for victory .',\n",
              "  40),\n",
              " ('So that there can be no possible misunderstanding , both Germany and Japan can be certain , beyond any shadow of a doubt , that America will continue the fight for freedom until no vestige of resistance remains !',\n",
              "  39),\n",
              " ('Mr . Speaker , Mr . President , Members of the Congress : It is with a heavy heart that I stand before you , my friends and colleagues , in the Congress of the United States .',\n",
              "  38),\n",
              " ('I want in turn to assure my fellow Americans and all of those who love peace and liberty throughout the world that I will support and defend those ideals with all my strength and all my heart .',\n",
              "  38),\n",
              " ('We are now carrying out our part of that strategy under the able direction of Admiral Leahy , General Marshall , A dmiral King , General Arnold , General Eisenhower , Admiral Nimitz and General MacArthur .',\n",
              "  37),\n",
              " ('Nothing is more essential to the future peace of the world than continued cooperation of the nations which had to muster the force necessary to defeat the conspiracy of the Axis powers to dominate the world .',\n",
              "  37),\n",
              " ('We must learn to trade more with other nations so that there may be - for our mutual advantage - increased product ion , increased employment and better standards of living throughout the world .',\n",
              "  35),\n",
              " ('With Divine guidance , and your help , we will find the new passage to a far better world , a kindly and friendly world , with just and lasting peace .',\n",
              "  32),\n",
              " ('To build a foundation of enduring peace we must not only work in harmony with our friends abroad , but we must have the united support of our own people .',\n",
              "  31),\n",
              " ('I appeal to every American , regardless of party , race , creed , or color , to support our efforts to build a strong and lasting United Nations Organization .',\n",
              "  31),\n",
              " ('With great humility I call upon all Americans to help me keep our nation united in defense of those ideals which have been so eloquently proclaimed by Franklin Roosevelt .',\n",
              "  30),\n",
              " ('Let me assure the forward - looking people of America that there w ill be no relaxation in our efforts to improve the lot of the common people .',\n",
              "  29),\n",
              " ('Yet , in this decisive hour , when world events are moving so rapidly , our silence might be misunderstood and might give comfort to our enemies .',\n",
              "  28),\n",
              " ('In His infinite wisdom , Almighty God has seen fit to take from us a great man who loved , and was beloved by , all humanity .',\n",
              "  28),\n",
              " (\"The grand strategy of the United Nations ' war has been determined - due in no small measure to the vision of our departed Commander in Chief .\",\n",
              "  28),\n",
              " (\"Hope was not enough to beat back the aggressors as long as the peace - loving nations were unwilling to come to each other ' s defense .\",\n",
              "  28),\n",
              " ('Having to pay such a heavy price to make complete victory certain , America will never become a party to any plan for partial victory !',\n",
              "  26),\n",
              " ('Lasting peace can never be secured if we permit our dangerous opponents to plot future wars with impunity at any mountain retreat - however distant .',\n",
              "  26),\n",
              " ('The responsibility for making of the peace - and it is a very grave responsibility - must rest with the defenders of the peace .',\n",
              "  25),\n",
              " ('At this moment , America , along with her brave Allies , is paying again a heavy price for the defense of our freedom .',\n",
              "  25),\n",
              " ('In the memory of those who have made the supreme sacrifice - in the memory of our fallen President - we shall not fail !',\n",
              "  25),\n",
              " ('We must not only have hope but we must have faith enough to work with other peace - loving nations to maintain the peace .',\n",
              "  25),\n",
              " ('If wars in the future are to be prevented the nations must be united in their determination to keep the peace under law .',\n",
              "  24),\n",
              " ('We shall need also an abiding faith in the people , the kind of faith and courage which Franklin Delano Roosevelt always had !',\n",
              "  24),\n",
              " ('Nothing shall shake our determination to punish the war criminals even though we must pursue them to the ends of the earth .',\n",
              "  23),\n",
              " ('Because of these sacrifices , the dawn of justice and freedom throughout th e world slowly casts its gleam across the horizon .',\n",
              "  23),\n",
              " ('With tragic fatalism , they insist that wars have always been , of necessity , and of necessity wars always will be .',\n",
              "  23),\n",
              " ('Even the most experienced pilot cannot bring a ship safely into harbor , unless he has the full cooperation of the crew .',\n",
              "  23),\n",
              " ('In the name of human decency and civilization , a more rational method of deciding national differences must and will be found !',\n",
              "  23),\n",
              " ('We will face the problems of peace with the same courage that we have faced and mastered the problems of war .',\n",
              "  22),\n",
              " ('To destroy greedy tyrants with dreams of world domination , we cannot continue in successive generations to sacrifice our finest youth .',\n",
              "  22),\n",
              " ('Here in America , we have labored long and hard to achieve a social order worthy of our great heritage .',\n",
              "  21),\n",
              " ('We well know today that such rights can be preserved only by constant vigilance , the eternal price of liberty !',\n",
              "  21),\n",
              " ('Within an hour after I took the oath of office , I announced that the San Francisco Conference would proceed .',\n",
              "  21),\n",
              " ('Only with your help can I hope to complete one of the greatest tasks ever assigned to a public servant .',\n",
              "  21),\n",
              " ('But the laws of Go d and of man have been violated and the guilty must not go unpunished .',\n",
              "  20),\n",
              " (\"The armies of liberation today are bringing to an end Hitler ' s ghastly threat to dominate the world .\",\n",
              "  20),\n",
              " ('Our debt to the heroic men and valiant women in the service of our country can never be repaid .',\n",
              "  20),\n",
              " ('During the dark hours of this horrible war , entire nations were kept going by something intangible - hope !',\n",
              "  20),\n",
              " ('When warned that abject submission offered the only salvation against overwhelming power , hope showed the way to victory .',\n",
              "  20),\n",
              " ('Only yesterday , we laid to rest the mortal remains of our beloved President , Franklin Delano Roosevelt .',\n",
              "  19),\n",
              " ('However , with the faith of our fathers in our hearts , we do not fear the future .',\n",
              "  19),\n",
              " ('I want the entire world to know that this direction must and will remain - unchanged and unhampered !',\n",
              "  19),\n",
              " ('Our forefathers came to our rugged shores in search of religious tolerance , political freedom and economic opportunity .',\n",
              "  19),\n",
              " ('No words can ease the aching hearts of untold millions of every race , creed and color .',\n",
              "  18),\n",
              " ('To settle for merely another temporary respite would surely jeopardize the future security of all the world .',\n",
              "  18),\n",
              " ('We have achieved a world leadership which does not depend solely upon our military and naval might .',\n",
              "  18),\n",
              " ('No man could possibly fill the tremendous void left by the passing of that noble soul .',\n",
              "  17),\n",
              " ('Today , the entire world is looking to America for enlightened leadership to peace and progress .',\n",
              "  17),\n",
              " ('We are deeply conscious of the fact that much hard fighting is still ahead of us .',\n",
              "  17),\n",
              " ('We will not traffic with the breakers of the peace on the terms of the peace .',\n",
              "  17),\n",
              " ('In our time , tremendous progress has been made toward a really democratic way of life .',\n",
              "  17),\n",
              " ('To such defeatism , men and women of good will must not and can not yield .',\n",
              "  17),\n",
              " ('The aggressors were beaten back only when the peace - loving nations united to defend themselves .',\n",
              "  17),\n",
              " ('The respon sibility of the great states is to serve and not to dominate the world .',\n",
              "  17),\n",
              " ('I ask only to be a good and faithful servant of my Lord and my people .',\n",
              "  17),\n",
              " ('It can be provided only by a united nation deeply devoted to the highest ideals .',\n",
              "  16),\n",
              " ('We shall never cease our struggle to preserve and maintain our American way of life .',\n",
              "  16),\n",
              " ('Gradually , the shackles of slavery are being broken by t he forces of freedom .',\n",
              "  16),\n",
              " ('Yet , without such organization , the rights of man on earth cannot be protected .',\n",
              "  16),\n",
              " ('The world will be doomed to deadly conflict , devoid of hope for real peace .',\n",
              "  16),\n",
              " ('Today , America has become one of the most powerful forces for good on earth .',\n",
              "  16),\n",
              " (\"PRESIDENT HARRY S . TRUMAN ' S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\",\n",
              "  15),\n",
              " ('In this shrinking world , it is futile to seek safety behind geographical barriers .',\n",
              "  15),\n",
              " ('In the difficult days ahead , unquestionably we shall face problems of staggering proportions .',\n",
              "  15),\n",
              " ('Without such machinery , the entire world will have to remain an armed camp .',\n",
              "  15),\n",
              " ('Past experience surely indicates that , without justice , an enduring peace becomes impossible .',\n",
              "  15),\n",
              " ('In bitter despair , some people have come to believe that wars are inevitable .',\n",
              "  15),\n",
              " ('As long as hope remains , the spirit of man will never be crushed .', 15),\n",
              " ('We have learned to fight with other nations in common defense of our freedom .',\n",
              "  15),\n",
              " ('In that way , America may well lead the world to peace and prosperity .',\n",
              "  15),\n",
              " ('The world knows it has lost a heroic champion of justice and freedom .',\n",
              "  14),\n",
              " ('On the battlefields , we have frequently faced overwhelming odds - and won !',\n",
              "  14),\n",
              " ('With characteristic energy , we are assisting in the liberation of entire nations .',\n",
              "  14),\n",
              " ('You , the Members of the Congress , surely know how I feel .', 14),\n",
              " ('We must now learn to live with other nations for our mutual good .', 14),\n",
              " ('The task of creating a sound international organization is complicated and difficult .',\n",
              "  13),\n",
              " ('Machi nery for the just settlement of international differences must be found .',\n",
              "  13),\n",
              " ('But hope alone was not and is not sufficient to avert war .', 13),\n",
              " ('For the benefit of all , every individual must do his duty .', 13),\n",
              " ('America must assist suffering humanity back along the path of peaceful progress .',\n",
              "  13),\n",
              " ('We must carry on . Our departed leader never looked backward .', 12),\n",
              " ('Our demand has been , and it remains - Unconditional Surrender !', 12),\n",
              " ('Real security will be found only in law and in justice .', 12),\n",
              " ('We must work , and if necessary , fight for it .', 12),\n",
              " ('Thoughtful people have always had faith that ultimately justice must triumph .',\n",
              "  12),\n",
              " ('Hope has become the secret weapon of the forces of liberation !', 12),\n",
              " ('At this moment , I have in my heart a prayer .', 12),\n",
              " ('That is my duty and I shall not shirk it .', 11),\n",
              " ('We do not wish to see unnecessary or unjustified suffering .', 11),\n",
              " ('Fortunately , people have retained hope for a durable peace .', 11),\n",
              " ('With confidence , I am depending upon all of you .', 11),\n",
              " ('May we Americans all live up to our glorious heritage .', 11),\n",
              " ('At a time like this , words are inadequate .', 10),\n",
              " ('The most eloquent tribute would be a reverent silence .', 10),\n",
              " ('That is what he would want us to do .', 10),\n",
              " ('Such a leadership requires vision , courage and tolerance .', 10),\n",
              " ('We are not unconscious of the dictates of humanity .', 10),\n",
              " ('At home , Americans will not be less resolute !', 10),\n",
              " ('All of us are praying for a speedy victory .', 10),\n",
              " ('Every day peace is delayed costs a terrible toll .', 10),\n",
              " ('For those fundamental rights , they risked their lives .', 10),\n",
              " ('Tragic fate has thrust upon us grave responsibilities .', 9),\n",
              " ('Tokyo rocks under the weight of our bombs .', 9),\n",
              " ('It is not enough to yearn for peace .', 9),\n",
              " ('The outlook for humanity is not so hopeless .', 9),\n",
              " ('Aggressors could not dominate the human mind .', 8),\n",
              " ('He looked forward and moved forward .', 7),\n",
              " ('That is what America will do .', 7),\n",
              " ('They have earned our undying gratitude .', 7),\n",
              " ('America will never forget their sacrifices .', 7),\n",
              " ('This will require time and tolerance .', 7),\n",
              " ('We must keep it so .', 6),\n",
              " ('April 16 , 1945', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "t8bFC7asUgwx",
        "outputId": "ae5fede0-64a0-4c59-daf0-791d6c85f99a"
      },
      "source": [
        "#6\n",
        "import textwrap\n",
        "long_string = 'She was the youngest of the two daughters of a most affectionate,indulgent father; and had, in consequence of her marriage,been mistress of his house from a very early period.Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short |of a mother in affection.'\n",
        "sentence_list = textwrap.wrap(long_string, width=60)\n",
        "len_of_sentences = [len(i) for i in sentence_list]\n",
        "for index,i in enumerate(sentence_list):\n",
        "  y = max(len_of_sentences) - len(i)\n",
        "  x_space = spaces(y)\n",
        "  if len(x_space) > index:\n",
        "    sentence_list[index]+=x_space[index]\n",
        "\n",
        "\n",
        "' '.join(sentence_list)\n",
        "\n",
        "textwrap.fill(long_string,60)\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'She was the youngest of the two daughters of a most\\naffectionate,indulgent father; and had, in consequence of\\nher marriage,been mistress of his house from a very early\\nperiod.Her mother had died too long ago for her to have more\\nthan an indistinct remembrance of her caresses; and her\\nplace had been supplied by an excellent woman as governess,\\nwho had fallen little short |of a mother in affection.'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3m3d9uqrKCj"
      },
      "source": [
        "def spaces(i):\n",
        "  return [' '*i]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyisO5SIyUFK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}